{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part I. ETL Pipeline for Pre-Processing the Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PLEASE RUN THE FOLLOWING CODE FOR PRE-PROCESSING THE FILES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Python packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Python packages \n",
    "import pandas as pd\n",
    "import cassandra\n",
    "import re\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import json\n",
    "import csv\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating list of filepaths to process original event csv data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check platform to determine if running jupyter notebook locally on a windows machine or a non-windows machine\n",
    "# change directory path accordingly\n",
    "platform = sys.platform\n",
    "if platform == \"win32\":\n",
    "    chdir_path = 'D:/Documents/GitHub/Udacity/Data-Engineering-Nanodegree/Data-Modeling-with-Cassandra'\n",
    "    os.chdir(chdir_path)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/workspace\n",
      "['/home/workspace/event_data/2018-11-18-events.csv', '/home/workspace/event_data/2018-11-15-events.csv', '/home/workspace/event_data/2018-11-16-events.csv', '/home/workspace/event_data/2018-11-09-events.csv', '/home/workspace/event_data/2018-11-11-events.csv', '/home/workspace/event_data/2018-11-17-events.csv', '/home/workspace/event_data/2018-11-14-events.csv', '/home/workspace/event_data/2018-11-02-events.csv', '/home/workspace/event_data/2018-11-27-events.csv', '/home/workspace/event_data/2018-11-13-events.csv', '/home/workspace/event_data/2018-11-26-events.csv', '/home/workspace/event_data/2018-11-03-events.csv', '/home/workspace/event_data/2018-11-19-events.csv', '/home/workspace/event_data/2018-11-25-events.csv', '/home/workspace/event_data/2018-11-04-events.csv', '/home/workspace/event_data/2018-11-29-events.csv', '/home/workspace/event_data/2018-11-01-events.csv', '/home/workspace/event_data/2018-11-06-events.csv', '/home/workspace/event_data/2018-11-24-events.csv', '/home/workspace/event_data/2018-11-22-events.csv', '/home/workspace/event_data/2018-11-30-events.csv', '/home/workspace/event_data/2018-11-10-events.csv', '/home/workspace/event_data/2018-11-28-events.csv', '/home/workspace/event_data/2018-11-07-events.csv', '/home/workspace/event_data/2018-11-21-events.csv', '/home/workspace/event_data/2018-11-08-events.csv', '/home/workspace/event_data/2018-11-05-events.csv', '/home/workspace/event_data/2018-11-23-events.csv', '/home/workspace/event_data/2018-11-12-events.csv', '/home/workspace/event_data/2018-11-20-events.csv']\n"
     ]
    }
   ],
   "source": [
    "# checking the current working directory\n",
    "print(os.getcwd())\n",
    "\n",
    "# Get the current folder and subfolder event data\n",
    "filepath = os.getcwd() + '/event_data'\n",
    "\n",
    "# Create a for loop to create a list of files and collect each filepath\n",
    "for root, dirs, files in os.walk(filepath):\n",
    "    \n",
    "# join the file path and roots with the subdirectories using glob\n",
    "    file_path_list = glob.glob(os.path.join(root,'*'))\n",
    "    print(file_path_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Processing the files to create the data file csv that will be used for Apache Casssandra tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiating an empty list of rows that will be generated from each file\n",
    "full_data_rows_list = [] \n",
    "    \n",
    "# for every filepath in the file path list \n",
    "for f in file_path_list:\n",
    "\n",
    "# reading csv file \n",
    "    with open(f, 'r', encoding = 'utf8', newline='') as csvfile: \n",
    "        # creating a csv reader object \n",
    "        csvreader = csv.reader(csvfile) \n",
    "        next(csvreader)\n",
    "        \n",
    " # extracting each data row one by one and append it        \n",
    "        for line in csvreader:\n",
    "            #print(line)\n",
    "            full_data_rows_list.append(line) \n",
    "            \n",
    "# uncomment the code below if you would like to get total number of rows \n",
    "#print(len(full_data_rows_list))\n",
    "# uncomment the code below if you would like to check to see what the list of event data rows will look like\n",
    "#print(full_data_rows_list)\n",
    "\n",
    "# creating a smaller event data csv file called event_datafile_full csv that will be used to insert data into the \\\n",
    "# Apache Cassandra tables\n",
    "csv.register_dialect('myDialect', quoting=csv.QUOTE_ALL, skipinitialspace=True)\n",
    "\n",
    "with open('event_datafile_new.csv', 'w', encoding = 'utf8', newline='') as f:\n",
    "    writer = csv.writer(f, dialect='myDialect')\n",
    "    writer.writerow(['artist','firstName','gender','itemInSession','lastName','length',\\\n",
    "                'level','location','sessionId','song','userId'])\n",
    "    for row in full_data_rows_list:\n",
    "        if (row[0] == ''):\n",
    "            continue\n",
    "        writer.writerow((row[0], row[2], row[3], row[4], row[5], row[6], row[7], row[8], row[12], row[13], row[16]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6821\n"
     ]
    }
   ],
   "source": [
    "# check the number of rows in the csv file\n",
    "with open('event_datafile_new.csv', 'r', encoding = 'utf8') as f:\n",
    "    print(sum(1 for line in f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part II. if the number of rows in the csv file equals 6821 proceed to the next cell... \n",
    "\n",
    "## Now we are ready to work with the CSV file titled <font color=red>event_datafile_new.csv</font>, located within the Workspace directory.  The event_datafile_new.csv contains the following columns: \n",
    "- artist \n",
    "- firstName of user\n",
    "- gender of user\n",
    "- item number in session\n",
    "- last name of user\n",
    "- length of the song\n",
    "- level (paid or free song)\n",
    "- location of the user\n",
    "- sessionId\n",
    "- song title\n",
    "- userId\n",
    "\n",
    "The image below is a screenshot of what the denormalized data should appear like in the <font color=red>**event_datafile_new.csv**</font> after the code above is run:<br>\n",
    "\n",
    "<img src=\"images/image_event_datafile_new.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cassandra.cluster import Cluster\n",
    "try: \n",
    "    cluster = Cluster(['127.0.0.1']) #If you have a locally installed Apache Cassandra instance\n",
    "    session = cluster.connect()\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Keyspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    session.execute(\"\"\"\n",
    "    CREATE KEYSPACE IF NOT EXISTS udacity \n",
    "    WITH REPLICATION = \n",
    "    { 'class' : 'SimpleStrategy', 'replication_factor' : 1 }\"\"\"\n",
    ")\n",
    "\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set Keyspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    session.set_keyspace('udacity')\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use Panda dataframes to add columns to the query output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pandas_factory(colnames, rows):\n",
    "    return pd.DataFrame(rows, columns=colnames)\n",
    "\n",
    "session.row_factory = pandas_factory\n",
    "session.default_fetch_size = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we need to create tables to run the following queries. Remember, with Apache Cassandra we model the database tables on the queries we want to run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sparkify would like the following questions/queries answered:\n",
    "\n",
    "### 1. Give me the artist, song title and song's length in the music app history that was heard during  sessionId = 338, and itemInSession  = 4\n",
    "\n",
    "\n",
    "### 2. Give me only the following: name of artist, song (sorted by itemInSession) and user (first and last name) for userid = 10, sessionid = 182\n",
    "    \n",
    "\n",
    "### 3. Give me every user name (first and last) in my music app history who listened to the song 'All Hands Against His Own'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### QUERY 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Query 1:  Give me the artist, song title and song's length in the music app history that was heard during \\\n",
    "## sessionId = 338, and itemInSession = 4\n",
    "\n",
    "query = \"DROP TABLE IF EXISTS artist_song_session\"\n",
    "try:\n",
    "    session.execute(query)\n",
    "except Exception as e:\n",
    "    print(e)  \n",
    "\n",
    "# rule of thumb... primary key with or without clustering columns must be unique\n",
    "# primary key will usually contain the columns that are in the where clause of the query\n",
    "# in this query, the primary key will be session_id and item_in_session which is necessary in order to satisfy uniqueness\n",
    "query = \"CREATE TABLE IF NOT EXISTS artist_song_session \"\n",
    "query = query + \"\"\"\n",
    "(session_id int\n",
    ",item_in_session int\n",
    ",artist_name text\n",
    ",song_title text\n",
    ",song_length float\n",
    ",user_id int\n",
    ",user_first_name text\n",
    ",user_last_name text\n",
    ",PRIMARY KEY (session_id, item_in_session))\n",
    "\"\"\"\n",
    "try:\n",
    "    session.execute(query)\n",
    "except Exception as e:\n",
    "    print(e)                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## insert into artist_song_session table\n",
    "\n",
    "# line[0] = artist\n",
    "# line[1] = firstName\n",
    "# line[2] = gender\n",
    "# line[3] = itemInSession\n",
    "# line[4] = lastName\n",
    "# line[5] = length\n",
    "# line[6] = level\n",
    "# line[7] = location\n",
    "# line[8] = sessionId\n",
    "# line[9] = song\n",
    "# line[10] = userId\n",
    "\n",
    "file = 'event_datafile_new.csv'\n",
    "\n",
    "query = \"\"\"\n",
    "INSERT INTO artist_song_session \n",
    "(session_id\n",
    ",item_in_session\n",
    ",artist_name\n",
    ",song_title\n",
    ",song_length\n",
    ")\n",
    "\"\"\"\n",
    "query = query + \" VALUES (%s, %s, %s, %s, %s)\"\n",
    "\n",
    "with open(file, encoding = 'utf8') as f:\n",
    "    csvreader = csv.reader(f)\n",
    "    next(csvreader) # skip header\n",
    "    for line in csvreader:\n",
    "        #print(line[5])\n",
    "        session.execute(query, (int(line[8]), int(line[3]), line[0], line[9], float(line[5])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Do a SELECT to verify that the data have been inserted into each table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  artist_name                       song_title  song_length\n",
      "0   Faithless  Music Matters (Mark Knight Dub)   495.307312\n"
     ]
    }
   ],
   "source": [
    "## Verify\n",
    "## Query 1:  Give me the artist, song title and song's length in the music app history that was heard during \\\n",
    "## sessionId = 338, and itemInSession = 4\n",
    "\n",
    "query = \"\"\"\n",
    "select artist_name\n",
    ",song_title\n",
    ",song_length \n",
    "from artist_song_session \n",
    "where session_id = 338 \n",
    "and item_in_session = 4\n",
    "\"\"\"\n",
    "try:\n",
    "    rslt = session.execute(query, timeout=None)\n",
    "    df = rslt._current_rows\n",
    "    print(df)\n",
    "except Exception as e:\n",
    "    print(e)                  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### QUERY 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Query 2: Give me only the following: name of artist, song (sorted by itemInSession) and user (first and last name)\\\n",
    "## for userid = 10, sessionid = 182\n",
    "\n",
    "query = \"DROP TABLE IF EXISTS artist_song_user\"\n",
    "try:\n",
    "    session.execute(query)\n",
    "except Exception as e:\n",
    "    print(e)  \n",
    "    \n",
    "# rule of thumb... primary key with or without clustering columns must be unique\n",
    "# primary key will usually contain the columns that are in the where clause of the query\n",
    "# in this query, the composite primary key will be user_id and session_id\n",
    "# item_in_session will be the clustering key - The Clustering Key is responsible for data sorting within the partition.\n",
    "query = \"CREATE TABLE IF NOT EXISTS artist_song_user \"\n",
    "query = query + \"\"\"\n",
    "(user_id int\n",
    ",session_id int\n",
    ",item_in_session int\n",
    ",artist_name text\n",
    ",song_title text\n",
    ",song_length float\n",
    ",user_first_name text\n",
    ",user_last_name text\n",
    ",PRIMARY KEY ((user_id, session_id), item_in_session))\n",
    "\"\"\"\n",
    "try:\n",
    "    session.execute(query)\n",
    "except Exception as e:\n",
    "    print(e)                 \n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## insert into artist_song_user table\n",
    "\n",
    "# line[0] = artist\n",
    "# line[1] = firstName\n",
    "# line[2] = gender\n",
    "# line[3] = itemInSession\n",
    "# line[4] = lastName\n",
    "# line[5] = length\n",
    "# line[6] = level\n",
    "# line[7] = location\n",
    "# line[8] = sessionId\n",
    "# line[9] = song\n",
    "# line[10] = userId\n",
    "\n",
    "file = 'event_datafile_new.csv'\n",
    "\n",
    "query = \"\"\"\n",
    "INSERT INTO artist_song_user \n",
    "(session_id\n",
    ",item_in_session\n",
    ",artist_name\n",
    ",song_title\n",
    ",song_length\n",
    ",user_id\n",
    ",user_first_name\n",
    ",user_last_name\n",
    ")\n",
    "\"\"\"\n",
    "query = query + \" VALUES (%s, %s, %s, %s, %s, %s, %s, %s)\"\n",
    "\n",
    "with open(file, encoding = 'utf8') as f:\n",
    "    csvreader = csv.reader(f)\n",
    "    next(csvreader) # skip header\n",
    "    for line in csvreader:\n",
    "        session.execute(query, (int(line[8]), int(line[3]), line[0], line[9], float(line[5]), int(line[10]), line[1], line[4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         artist_name                                         song_title  \\\n",
      "0   Down To The Bone                                 Keep On Keepin' On   \n",
      "1       Three Drives                                        Greece 2000   \n",
      "2  Sebastien Tellier                                          Kilometer   \n",
      "3      Lonnie Gordon  Catch You Baby (Steve Pitron & Max Sanna Radio...   \n",
      "\n",
      "  user_first_name user_last_name  \n",
      "0          Sylvie           Cruz  \n",
      "1          Sylvie           Cruz  \n",
      "2          Sylvie           Cruz  \n",
      "3          Sylvie           Cruz  \n"
     ]
    }
   ],
   "source": [
    "## Verify\n",
    "## Query 2: Give me only the following: name of artist, song (sorted by itemInSession) and user (first and last name)\\\n",
    "## for userid = 10, sessionid = 182\n",
    "\n",
    "query = \"\"\"\n",
    "select artist_name\n",
    ",song_title\n",
    ",user_first_name\n",
    ",user_last_name \n",
    "from artist_song_user \n",
    "where user_id = 10 \n",
    "and session_id = 182\n",
    "\"\"\"\n",
    "try:\n",
    "    rslt = session.execute(query, timeout=None)\n",
    "    df = rslt._current_rows\n",
    "    print(df)\n",
    "except Exception as e:\n",
    "    print(e)                  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### QUERY 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Query 3: Give me every user name (first and last) in my music app history who listened to the song 'All Hands Against His Own'\n",
    "\n",
    "query = \"DROP TABLE IF EXISTS user_song\"\n",
    "try:\n",
    "    session.execute(query)\n",
    "except Exception as e:\n",
    "    print(e)  \n",
    "    \n",
    "# rule of thumb... primary key with or without clustering columns must be unique\n",
    "# primary key will usually contain the columns that are in the where clause of the query\n",
    "# in this query, the primary key will be song_title, user_id which is necessary in order to satisfy uniqueness\n",
    "query = \"CREATE TABLE IF NOT EXISTS user_song \"\n",
    "query = query + \"\"\"\n",
    "(song_title text\n",
    ",user_id int\n",
    ",user_first_name text\n",
    ",user_last_name text\n",
    ",PRIMARY KEY (song_title, user_id))\n",
    "\"\"\"\n",
    "try:\n",
    "    session.execute(query)\n",
    "except Exception as e:\n",
    "    print(e)                 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## insert into user_song table\n",
    "\n",
    "# line[0] = artist\n",
    "# line[1] = firstName\n",
    "# line[2] = gender\n",
    "# line[3] = itemInSession\n",
    "# line[4] = lastName\n",
    "# line[5] = length\n",
    "# line[6] = level\n",
    "# line[7] = location\n",
    "# line[8] = sessionId\n",
    "# line[9] = song\n",
    "# line[10] = userId\n",
    "\n",
    "file = 'event_datafile_new.csv'\n",
    "\n",
    "query = \"\"\"\n",
    "INSERT INTO user_song \n",
    "(song_title\n",
    ",user_id\n",
    ",user_first_name\n",
    ",user_last_name)\n",
    "\"\"\"\n",
    "query = query + \" VALUES (%s, %s, %s, %s)\"\n",
    "\n",
    "with open(file, encoding = 'utf8') as f:\n",
    "    csvreader = csv.reader(f)\n",
    "    next(csvreader) # skip header\n",
    "    for line in csvreader:\n",
    "        session.execute(query, (line[9], int(line[10]), line[1], line[4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  user_first_name user_last_name\n",
      "0      Jacqueline          Lynch\n",
      "1           Tegan         Levine\n",
      "2            Sara        Johnson\n"
     ]
    }
   ],
   "source": [
    "## Verify\n",
    "## Query 3: Give me every user name (first and last) in my music app history who listened to the song 'All Hands Against His Own'\n",
    "\n",
    "query = \"select user_first_name, user_last_name from user_song where song_title = 'All Hands Against His Own'\"\n",
    "try:\n",
    "    rslt = session.execute(query, timeout=None)\n",
    "    df = rslt._current_rows\n",
    "    print(df)\n",
    "except Exception as e:\n",
    "    print(e)                  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop the tables before closing out the sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Drop the table before closing out the sessions\n",
    "\n",
    "query = \"DROP TABLE IF EXISTS artist_song_session\"\n",
    "try:\n",
    "    session.execute(query)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    \n",
    "query = \"DROP TABLE IF EXISTS artist_song_user\"\n",
    "try:\n",
    "    session.execute(query)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    \n",
    "query = \"DROP TABLE IF EXISTS user_song\"\n",
    "try:\n",
    "    session.execute(query)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Close the session and cluster connectionÂ¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.shutdown()\n",
    "cluster.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
